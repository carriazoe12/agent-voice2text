# ü§ñ Procesamiento y Transcripci√≥n de Llamadas de Call Center

> Sistema de procesamiento de audio y transcripci√≥n inteligente para llamadas de agentes de call center, desarrollado en Python con procesamiento local y an√°lisis de IA.

## üìã Descripci√≥n del Proyecto

Este proyecto implementa una soluci√≥n completa para el procesamiento y an√°lisis de llamadas de call center, cumpliendo con los siguientes requerimientos:

- **Transcripci√≥n local** utilizando Whisper (local)
- **Preprocesamiento de audio** con filtros y limpieza
- **Identificaci√≥n autom√°tica** del di√°logo del agente mediante LLM
- **Limpieza y estandarizaci√≥n** del texto resultante

### üéØ Caracter√≠sticas Principales

‚úÖ **Procesamiento Local Completo**: Transcripci√≥n y an√°lisis sin dependencias de servicios externos (excepto OpenAI para extracci√≥n de agente)

‚úÖ **Preprocesamiento Avanzado**: Conversi√≥n a mono, normalizaci√≥n, filtros de ruido y eliminaci√≥n de silencios

‚úÖ **Diarizaci√≥n Opcional**: Soporte para identificaci√≥n de hablantes usando pyannote-whisper

‚úÖ **Interfaz Web Intuitiva**: Aplicaci√≥n Streamlit con dise√±o responsive y feedback en tiempo real

‚úÖ **Manejo Robusto de Errores**: Validaciones y recuperaci√≥n ante fallos en el procesamiento

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerequisitos del Sistema

- **Python 3.10+**
- **FFmpeg** instalado y configurado en el PATH del sistema

#### Instalaci√≥n de FFmpeg

| Sistema Operativo | Comando |
|-------------------|---------|
| Windows (Chocolatey) | `choco install ffmpeg` |
| macOS (Homebrew) | `brew install ffmpeg` |
| Ubuntu/Debian | `sudo apt-get install ffmpeg` |
| CentOS/RHEL | `sudo yum install ffmpeg` |

### Configuraci√≥n del Entorno

1. **Clonar el repositorio**
```bash
git clone https://github.com/carriazoe12/agent-voice2text.git
cd agent-voice2text
```

2. **Crear entorno virtual**
```bash
python -m venv venv
```

3. **Activar entorno virtual**
```bash
# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

4. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

### Configuraci√≥n de Tokens (Opcional)

Para utilizar la funcionalidad de diarizaci√≥n de hablantes, necesitar√°s configurar un token de Hugging Face:

1. **Crear cuenta en [Hugging Face](https://huggingface.co)**
2. **Obtener acceso al modelo de diarizaci√≥n:**
   - Visita [pyannote/segmentation](https://huggingface.co/pyannote/segmentation)
   - Haz clic en "Accept" para aceptar los t√©rminos de uso
   - Esto es necesario para acceder a los modelos de diarizaci√≥n
3. **Generar token de acceso:**
   - Ve a [Settings ‚Üí Access Tokens](https://huggingface.co/settings/tokens)
   - Crea un nuevo token con permisos de lectura
4. **Configurar en el proyecto:**
   - Crear archivo `.env` en la ra√≠z del proyecto:
```env
HUGGINGFACE_TOKEN=hf_XXXXXXXXXXXXXXXXXXXXXXXX
```

## üéÆ Uso de la Aplicaci√≥n

### Ejecuci√≥n B√°sica

```bash
streamlit run main.py
```

La aplicaci√≥n estar√° disponible en `http://localhost:8501`

### Flujo de Trabajo

1. **Configuraci√≥n Inicial**
   - Ingresa tu OpenAI API Key en la barra lateral
   - (Opcional) Configura el token de Hugging Face para diarizaci√≥n

2. **Carga de Audio**
   - Sube un archivo de audio (`.wav`, `.mp3`, `.m4a`)
   - El sistema validar√° el formato y mostrar√° una vista previa

3. **Procesamiento**
   - Haz clic en "Procesar con IA"
   - El sistema ejecutar√° el pipeline completo:
     - Preprocesamiento de audio
     - Transcripci√≥n con Whisper
     - Extracci√≥n del di√°logo del agente
     - Limpieza y estandarizaci√≥n

4. **Resultados**
   - Revisa la transcripci√≥n completa
   - Descarga el texto final del agente
   - Los archivos se guardan autom√°ticamente en las carpetas correspondientes

### üîÑ Cambiar entre Modos de Transcripci√≥n

El sistema viene configurado por defecto en **modo b√°sico** (Whisper). Para activar el **modo con diarizaci√≥n**, debes modificar el archivo `main.py`:

**En el archivo `main.py`, l√≠neas 76-80:**

```python
st.write("2Ô∏è‚É£ **Transcribiendo la conversaci√≥n completa (Agente y Cliente)...**")
transcripcion_completa = transcribir_audio(audio_preprocesado_path)
# Alternativa con diarizaci√≥n local (Whisper + pyannote): 
#transcripcion_completa = transcribir_audio_diarizado(audio_preprocesado_path)   
```

**Para activar la diarizaci√≥n:**
1. Comenta la l√≠nea 77: `# transcripcion_completa = transcribir_audio(audio_preprocesado_path)`
2. Descomenta la l√≠nea 79: `transcripcion_completa = transcribir_audio_diarizado(audio_preprocesado_path)`

**Resultado final:**
```python
st.write("2Ô∏è‚É£ **Transcribiendo la conversaci√≥n completa (Agente y Cliente)...**")
# transcripcion_completa = transcribir_audio(audio_preprocesado_path)
# Alternativa con diarizaci√≥n local (Whisper + pyannote): 
transcripcion_completa = transcribir_audio_diarizado(audio_preprocesado_path)   
```

> **Nota**: Aseg√∫rate de tener configurado el token de Hugging Face en el archivo `.env` antes de usar el modo con diarizaci√≥n.

## üìÅ Estructura del Proyecto

```
Indratask/
‚îú‚îÄ‚îÄ main.py                          # Aplicaci√≥n principal Streamlit
‚îú‚îÄ‚îÄ requirements.txt                 # Dependencias del proyecto
‚îú‚îÄ‚îÄ README.md                        # Documentaci√≥n
‚îú‚îÄ‚îÄ .env                            # Variables de entorno (opcional)
‚îú‚îÄ‚îÄ audio_in/                       # Archivos de audio de entrada
‚îú‚îÄ‚îÄ audio_out/                      # Audio preprocesado
‚îú‚îÄ‚îÄ transcripciones/                # Transcripciones finales
‚îú‚îÄ‚îÄ venv/                           # Entorno virtual
‚îî‚îÄ‚îÄ utils/                          # M√≥dulos de utilidades
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ preprocesar_audio.py        # Preprocesamiento de audio
    ‚îú‚îÄ‚îÄ transcribir_audio.py        # Transcripci√≥n con Whisper
    ‚îú‚îÄ‚îÄ transcribir_audio_diarizado.py  # Transcripci√≥n con diarizaci√≥n
    ‚îú‚îÄ‚îÄ analisis_llm.py             # An√°lisis con OpenAI
    ‚îî‚îÄ‚îÄ limpiar_texto.py            # Limpieza de texto
```

## üîß Funcionalidades T√©cnicas

### Preprocesamiento de Audio

El sistema implementa un pipeline robusto de preprocesamiento:

- **Conversi√≥n a Mono**: Unificaci√≥n de canales para mejor compatibilidad
- **Normalizaci√≥n**: Ajuste autom√°tico de niveles de volumen
- **Filtros de Ruido**: Eliminaci√≥n de frecuencias problem√°ticas (100Hz - 8kHz)
- **Eliminaci√≥n de Silencios**: Corte autom√°tico de pausas prolongadas

### Transcripci√≥n Inteligente

El sistema ofrece dos enfoques para la transcripci√≥n, cada uno con sus ventajas:

#### **Modo B√°sico (Whisper)**
- Transcripci√≥n local completa de la conversaci√≥n
- Optimizaci√≥n de memoria con carga √∫nica del modelo
- Soporte para m√∫ltiples idiomas
- Procesamiento m√°s r√°pido
- Requiere an√°lisis posterior con LLM para identificar al agente

#### **Modo Avanzado (Diarizaci√≥n)**
- Identificaci√≥n autom√°tica de hablantes (SPEAKER_00, SPEAKER_01, etc.)
- Combinaci√≥n de Whisper + pyannote.audio
- Mayor precisi√≥n en la identificaci√≥n del agente
- Mejor separaci√≥n entre agente y cliente

### üîç Comparaci√≥n de Modos: B√°sico vs Diarizaci√≥n

#### **Ejemplo de Mejora en Precisi√≥n**

**Modo B√°sico - Error detectado:**
![Error en modo b√°sico](images/error_modo_basico.png)
*El modo b√°sico cometi√≥ un error de 1 palabra en la transcripci√≥n*

**Modo Diarizaci√≥n - Mejor precisi√≥n:**
![Mejora con diarizaci√≥n](images/mejora_con_diarizacion.png)
*El modo con diarizaci√≥n corrigi√≥ el error y mejor√≥ la precisi√≥n general*

> **Nota**: La diarizaci√≥n requiere un token de Hugging Face para descargar los modelos de identificaci√≥n de hablantes, pero la inferencia se realiza completamente de forma local.

### An√°lisis con LLM

El sistema utiliza OpenAI GPT para:
- Identificar y extraer √∫nicamente el di√°logo del agente
- Mantener contexto y coherencia del discurso
- Adaptarse a diferentes estilos de comunicaci√≥n

### Limpieza de Texto

Proceso de estandarizaci√≥n que incluye:
- Conversi√≥n a may√∫sculas
- Eliminaci√≥n de signos de puntuaci√≥n
- Preservaci√≥n de caracteres especiales del espa√±ol (√°, √©, √≠, √≥, √∫, √±)
- Normalizaci√≥n de espacios

## üìä Ejemplo de Entrada y Salida

### Archivo de Entrada
```
audio_in/llamada_ejemplo_1.wav
```

### Salida Procesada

**Transcripci√≥n Completa (Modo B√°sico - Whisper):**
```
Buenos d√≠as, le atiende Mar√≠a del servicio al cliente. ¬øEn qu√© puedo ayudarle?
Hola, tengo un problema con mi factura...
Entiendo, perm√≠tame verificar su informaci√≥n...
```

**Transcripci√≥n Completa (Modo Diarizaci√≥n - Whisper + pyannote):**
```
SPEAKER_00: Buenos d√≠as, le atiende Mar√≠a del servicio al cliente. ¬øEn qu√© puedo ayudarle?
SPEAKER_01: Hola, tengo un problema con mi factura...
SPEAKER_00: Entiendo, perm√≠tame verificar su informaci√≥n...
```

**Texto Final del Agente (Limpio):**
```
BUENOS DIAS LE ATIENDE MARIA DEL SERVICIO AL CLIENTE EN QUE PUEDO AYUDARLE
ENTIENDO PERMITAME VERIFICAR SU INFORMACION
```

### Archivos Generados

- `audio_out/llamada_ejemplo_1_preprocesado.wav` - Audio limpio
- `transcripciones/llamada_ejemplo_1_agente.txt` - Texto final del agente

## üõ†Ô∏è Soluci√≥n de Problemas

### Errores Comunes

| Error | Soluci√≥n |
|-------|----------|
| `FFmpeg not found` | Instalar FFmpeg y agregar al PATH del sistema |
| `NumPy version conflict` | Usar `numpy==1.26.4` como especificado en requirements.txt |
| `OpenAI API error` | Verificar que la API Key sea v√°lida y tenga cr√©ditos |
| `Hugging Face token error` | Crear token en huggingface.co y configurar en .env |

### Optimizaci√≥n de Rendimiento

- **Para audios largos**: Considerar usar el modelo Whisper "small" o "medium"
- **Para mejor precisi√≥n**: Activar la diarizaci√≥n con token de Hugging Face
- **Para procesamiento r√°pido**: Usar GPU si est√° disponible (PyTorch CUDA)

## üîó Enlaces √ötiles

- [Documentaci√≥n de Whisper](https://github.com/openai/whisper)
- [pyannote-whisper](https://github.com/yinruiqing/pyannote-whisper)
- [pyannote/segmentation](https://huggingface.co/pyannote/segmentation) - Modelo de diarizaci√≥n
- [Documentaci√≥n de Streamlit](https://docs.streamlit.io/)
- [FFmpeg](https://ffmpeg.org/)

## üë®‚Äçüíª Autor

**Eduardo Ahumada Carriazo**

---



